{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ae309fe-c8ed-462a-8abb-9159dd3971c8",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Written at Atlas Fellowship Summer Program, 15 August 2022.\n",
    "\n",
    "Building a neural network with NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b366fca-798d-4c30-bb30-889f1fc5621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e54bf-6828-4b69-9e6d-f4c023683947",
   "metadata": {},
   "source": [
    "## Shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d431bd85-2656-4509-8104-b5c759a00a7b",
   "metadata": {},
   "source": [
    "The shape is a `List` of the `len`s: outermost to innermost:\n",
    "e.g.\n",
    "```py\n",
    ">>> np.shape([[[1, 2, 3], [4, 5, 6]]]) == (1, 2, 3)\n",
    "True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb3eccf-115d-4a84-9c1f-ecfffeb8297c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 0],\n",
       "       [1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.random.randint(low=0, high=2, size=(1000, 2))\n",
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c66b1-10a4-4337-98ac-15aef4fdc0b4",
   "metadata": {},
   "source": [
    "## The Slicing Notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6d1593-786f-4d5e-be83-114d38d1f128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:5, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040b966b-9863-41a8-9a46-304b45b15e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.expand_dims(train_x[:, 0] & train_x[:, 1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b973439-8611-4d30-860d-a067b044c343",
   "metadata": {},
   "source": [
    "## Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfc00b3-232e-47b6-a9b1-24f7952b0e74",
   "metadata": {},
   "source": [
    "Neural networks: we want to approximate any function... but neurons are linear.\n",
    "\n",
    "Activation functions: introduce non-linearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18010e3-7f01-45b8-9e58-4e16c29b0896",
   "metadata": {},
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec8669b-5826-4bb1-bc33-0b96b5bc9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b580941-7383-4bd1-a69c-8868bec81ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. ],\n",
       "       [0. , 0. ],\n",
       "       [0. , 0.5],\n",
       "       ...,\n",
       "       [0. , 0. ],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(train_x - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9f8a5-73f5-4e00-8037-1e0b4bc6ee51",
   "metadata": {},
   "source": [
    "Nice. This implementation works and works with an array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4768e6be-0556-43ce-a82a-77f01f987222",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ed6de-1880-40b6-9178-dec161ceee63",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathrm{sigmoid}(x) := \\frac{1}{1 + \\exp(-x)}\n",
    "$$\n",
    "\n",
    "Unlike `relu`, `sigmoid` makes the layer's output \"the larger, the better\" if the goal is to converge to a single target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a7663b-e221-43dd-9bce-abdcfec14db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84e79292-3b70-49f1-84e8-a2bc3fe28d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.5       , 0.73105858],\n",
       "       ...,\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.73105858, 0.73105858],\n",
       "       [0.73105858, 0.73105858]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52ba28e7-a742-449e-b028-d44aeaa5785a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN:\n",
    "    \"\"\"Simple neural network:\n",
    "    x1\\\n",
    "        -> [10] -> [1]\n",
    "    x2/\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # (input, output) == (2, 10)\n",
    "        self.l1_weights = np.random.normal(size=(2, 10))\n",
    "        self.l1_bias = np.random.normal(size=(1, 10))\n",
    "        # (input, output) == (10, 1)\n",
    "        self.l2_weights = np.random.normal(size=(10, 1))\n",
    "        self.l2_bias = np.random.normal(size=(1, 1))\n",
    "        self.step = {}\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.step[\"l1_out\"] = (x @ self.l1_weights) + self.l1_bias\n",
    "        self.step[\"l1_actv\"] = relu(self.step[\"l1_out\"])\n",
    "\n",
    "        self.step[\"l2_out\"] = (self.step[\"l1_actv\"] @ self.l2_weights) + self.l2_bias\n",
    "        self.step[\"l2_actv\"] = sigmoid(self.step[\"l2_out\"])\n",
    "        \n",
    "        return self.step[\"l2_actv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec3f23-3a5d-4afc-a4e6-2d44fae577b8",
   "metadata": {},
   "source": [
    "`@` is a suger for matrix multiplication (it calls `object.__matmul__`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fdc1449-2b7a-49ff-9998-049db65de781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2]) @ np.array([[1], [2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98af7d03-ab26-48fe-af47-da4cd9dab5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nn = SimpleNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a5a813-2498-4d3a-bd26-774069d745e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94969103],\n",
       "       [0.94969103],\n",
       "       [0.81894128],\n",
       "       [0.94146972],\n",
       "       [0.94146972]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y_1 = my_nn.forward(train_x)\n",
    "pred_y_1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "346adb66-cc6d-4811-8d98-3a3504c56713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_loss(pred_y, y):\n",
    "    return np.sqrt(np.mean((pred_y - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a41f1652-a433-4e9d-ad8a-22971bcc0563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7914148259409336"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms_loss(pred_y_1, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f7309-a116-4904-9454-d9975979f58b",
   "metadata": {},
   "source": [
    "We don't need the units to be the same though, so we can omit `sqrt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a850000-ad84-4d98-a5fc-2bdfddcafa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms_loss(pred_y, y):\n",
    "    return np.mean((pred_y - y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ca1e45c-a7d4-4f92-9f40-ed7937026f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263374267191182"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms_loss(pred_y_1, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bf93d9-667a-49b8-b76c-f6df721542bc",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616bebc-645e-4183-b805-d2b70496c89f",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\Delta\\mathrm{param} = \\frac{\\partial \\mathrm{loss}}{\\partial \\mathrm{param}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fac9934-4058-41ab-a151-4b79f597c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_relu(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    # Official form:\n",
    "    # return sigmoid(x) * (1 - sigmoid(x))\n",
    "    # I want to do it by hand:\n",
    "    # return -1 * (1. + np.exp(-x)) ** -2 * -1 * np.exp(-x)\n",
    "    # return (1. + np.exp(-x)) ** -2 * np.exp(-x)\n",
    "    # We can prove they are equal\n",
    "    return np.exp(x) / (1. + np.exp(x)) ** 2\n",
    "\n",
    "def d_ms_loss(pred_y, y):\n",
    "    return np.mean(2 * (pred_y - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a68838-6ee9-46a1-9057-e6bb6a1e771a",
   "metadata": {},
   "source": [
    "Create a new NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c078ffc-7eb8-4854-b157-921a49e481d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = SimpleNN()\n",
    "all_total_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6367b95-1908-48cd-a93e-dd1b62414741",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "max_epoch = 100\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    total_loss = 0\n",
    "    for (x, y) in zip(train_x, train_y):\n",
    "        cur_pred_y = nn.forward(x)\n",
    "        cur_loss = ms_loss(cur_pred_y, y)\n",
    "        total_loss += cur_loss\n",
    "\n",
    "        # Loss := loss(L2actv - y)\n",
    "        par_loss_par_l2actv = d_ms_loss(nn.step[\"l2_actv\"], y)\n",
    "        # L2actv := L2actv(L2out)\n",
    "        par_l2actv_par_l2out = d_sigmoid(nn.step[\"l2_out\"])\n",
    "        # L2out := L1actv @ weights2 + bias2\n",
    "        par_l2out_par_bias2 = 1\n",
    "        par_l2out_par_weights2 = nn.step[\"l1_actv\"].T\n",
    "        par_l2out_par_l1actv = nn.l2_weights.T\n",
    "        # L1actv := L1actv(L1out)\n",
    "        par_l1actv_par_l1out = d_relu(nn.step[\"l1_out\"])\n",
    "        # L1out := x @ weights1 + bias1\n",
    "        par_l1out_par_bias1 = 1\n",
    "        par_l1out_par_weights1 = np.expand_dims(x, 1)\n",
    "        \n",
    "        # Now we use the chain rule\n",
    "        par_loss_par_bias2 = par_loss_par_l2actv * par_l2actv_par_l2out \\\n",
    "            * par_l2out_par_bias2\n",
    "        par_loss_par_weights2 = par_loss_par_l2actv * par_l2actv_par_l2out \\\n",
    "            * par_l2out_par_weights2\n",
    "        par_loss_par_bias1 = par_loss_par_l2actv * par_l2actv_par_l2out \\\n",
    "            * par_l2out_par_l1actv * par_l1actv_par_l1out * par_l1out_par_bias1\n",
    "        par_loss_par_weights1 = par_loss_par_l2actv * par_l2actv_par_l2out \\\n",
    "            * par_l2out_par_l1actv * par_l1actv_par_l1out * par_l1out_par_weights1\n",
    "\n",
    "        # Then, we update the weights and biases\n",
    "        nn.l2_bias -= learning_rate * par_loss_par_bias2\n",
    "        nn.l2_weights -= learning_rate * par_loss_par_weights2\n",
    "        nn.l1_bias -= learning_rate * par_loss_par_bias1\n",
    "        nn.l1_weights -= learning_rate * par_loss_par_weights1\n",
    "    all_total_losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c355c471",
   "metadata": {},
   "source": [
    "Let's hope that the loss decreses over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cacc130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15cf8f340>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(all_total_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c3baa4d-a9f3-4ad7-a5e0-6016fa75bfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(nn.forward([[0, 0], [1, 0], [0, 1], [1, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab97c188-8353-473e-89fc-d24176ea4270",
   "metadata": {},
   "source": [
    "## Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5aa0e",
   "metadata": {},
   "source": [
    "A convolutional layer is a function (kernel function) that applies to some consecutive outputs of the previous layer (or the input). For example, if the previous layer outputs\n",
    "```py\n",
    "[1, 8, 9, -2, 3, 4, 8, 5]\n",
    "```\n",
    "and in the convolutional layer, we multiply each pair of inputs with `[1, -1]`, we get\n",
    "```py\n",
    "[1 - 8, 8 - 9, 9 + 2, -2 - 3, 3 - 4, 4 - 8, 8 - 5]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "63c2a4662a769bf482a00610948abf480804b022afb88b874cc2b35069915039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
